{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0187b82",
   "metadata": {},
   "source": [
    "# Phase B ? BERT-large + LoRA\n",
    "\n",
    "Applies LoRA adapters to BERT-large and fine-tunes for a single epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5045d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    current = Path.cwd().resolve()\n",
    "    for path in [current, *current.parents]:\n",
    "        if (path / \"src\").exists() and (path / \"notebooks\").exists():\n",
    "            return path\n",
    "    raise RuntimeError(\"Unable to locate the repository root. Please run this notebook from inside the project.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "os.chdir(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from src import cost, data, eval as eval_utils, models, train, utils\n",
    "from src.eval import trainer_compute_metrics\n",
    "from src.utils import GLOBAL_CONFIG, configure_tf32, set_seed_everywhere\n",
    "\n",
    "model_name = \"bert-large-uncased\"\n",
    "lora_targets = [\"query\", \"key\", \"value\"]\n",
    "\n",
    "set_seed_everywhere(GLOBAL_CONFIG.seed)\n",
    "configure_tf32(GLOBAL_CONFIG.tf32)\n",
    "\n",
    "dataset = data.load_sst2()\n",
    "model, tokenizer = models.load_model_and_tokenizer(model_name)\n",
    "model = models.apply_lora(model, target_modules=lora_targets, r=32, alpha=64, dropout=0.1)\n",
    "models.enable_gradient_checkpointing(model)\n",
    "models.enable_input_require_grads(model)\n",
    "\n",
    "tokenized = data.tokenize_text_dataset(dataset, tokenizer, GLOBAL_CONFIG.max_length)\n",
    "train_dataset = data.format_for_torch(tokenized[\"train\"])\n",
    "validation_dataset = data.format_for_torch(tokenized[\"validation\"])\n",
    "test_dataset = data.format_for_torch(tokenized[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329cf48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = train.build_training_arguments(\n",
    "    output_dir=\"outputs/runs/phase_b_lora\",\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-4,\n",
    "    gradient_checkpointing=True,\n",
    ")\n",
    "\n",
    "trainer = train.create_trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    training_args=training_args,\n",
    "    compute_metrics=trainer_compute_metrics,\n",
    ")\n",
    "\n",
    "train_metrics, eval_metrics = train.train_and_evaluate(trainer)\n",
    "test_metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
    "display(eval_metrics)\n",
    "display(test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reports_dir = utils.ensure_dir(\"outputs/reports\")\n",
    "param_counts = cost.count_parameters(model)\n",
    "train_seconds = float(train_metrics.get(\"train_runtime\", 0.0))\n",
    "efficiency = cost.efficiency_metrics(\n",
    "    accuracy=eval_metrics.get(\"eval_accuracy\", 0.0),\n",
    "    trainable_params=param_counts[\"trainable\"],\n",
    "    train_seconds=train_seconds,\n",
    ")\n",
    "\n",
    "metrics = {\n",
    "    \"phase\": \"B\",\n",
    "    \"model\": model_name,\n",
    "    \"train_runtime_seconds\": train_seconds,\n",
    "    \"dev\": eval_metrics,\n",
    "    \"test\": test_metrics,\n",
    "    \"parameter_counts\": param_counts,\n",
    "    \"efficiency\": efficiency,\n",
    "}\n",
    "utils.write_json(metrics, reports_dir / \"phase_b_metrics.json\")\n",
    "metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
