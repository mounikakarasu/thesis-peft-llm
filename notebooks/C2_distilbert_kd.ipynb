{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7448e5",
   "metadata": {},
   "source": [
    "# Phase C2 ? DistilBERT KD (1k samples)\n",
    "\n",
    "Fine-tunes DistilBERT with knowledge distillation using the 1k KD set generated in Phase A.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    current = Path.cwd().resolve()\n",
    "    for path in [current, *current.parents]:\n",
    "        if (path / \"src\").exists() and (path / \"notebooks\").exists():\n",
    "            return path\n",
    "    raise RuntimeError(\"Unable to locate the repository root. Please run this notebook from inside the project.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "os.chdir(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5995d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from src import cost, data, eval as eval_utils, kd, models, train, utils\n",
    "from src.eval import trainer_compute_metrics\n",
    "from src.utils import GLOBAL_CONFIG, configure_tf32, set_seed_everywhere\n",
    "\n",
    "kd_path = Path(\"outputs/kd/kd_1000\")\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "if not kd_path.exists():\n",
    "    raise FileNotFoundError(\"KD subset missing. Run the Phase A notebook first.\")\n",
    "\n",
    "set_seed_everywhere(GLOBAL_CONFIG.seed)\n",
    "configure_tf32(GLOBAL_CONFIG.tf32)\n",
    "\n",
    "dataset = data.load_sst2()\n",
    "kd_raw = data.load_local_dataset(kd_path)\n",
    "model, tokenizer = models.load_model_and_tokenizer(model_name)\n",
    "\n",
    "tokenized = data.tokenize_text_dataset(dataset, tokenizer, GLOBAL_CONFIG.max_length)\n",
    "validation_dataset = data.format_for_torch(tokenized[\"validation\"])\n",
    "test_dataset = data.format_for_torch(tokenized[\"test\"])\n",
    "\n",
    "kd_tokenized = data.tokenize_text_dataset(kd_raw, tokenizer, GLOBAL_CONFIG.max_length)\n",
    "kd_train_dataset = data.format_for_torch(kd_tokenized, include_teacher_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99209530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = train.build_training_arguments(\n",
    "    output_dir=\"outputs/runs/phase_c2_distilbert_kd\",\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-5,\n",
    ")\n",
    "\n",
    "trainer = train.create_trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=kd_train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    training_args=training_args,\n",
    "    compute_metrics=trainer_compute_metrics,\n",
    "    trainer_cls=kd.DistillationTrainer,\n",
    "    alpha=0.7,\n",
    "    temperature=2.0,\n",
    ")\n",
    "\n",
    "train_metrics, eval_metrics = train.train_and_evaluate(trainer)\n",
    "test_metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
    "display(eval_metrics)\n",
    "display(test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb305c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reports_dir = utils.ensure_dir(\"outputs/reports\")\n",
    "param_counts = cost.count_parameters(model)\n",
    "train_seconds = float(train_metrics.get(\"train_runtime\", 0.0))\n",
    "efficiency = cost.efficiency_metrics(\n",
    "    accuracy=eval_metrics.get(\"eval_accuracy\", 0.0),\n",
    "    trainable_params=param_counts[\"trainable\"],\n",
    "    train_seconds=train_seconds,\n",
    ")\n",
    "\n",
    "metrics = {\n",
    "    \"phase\": \"C2\",\n",
    "    \"model\": model_name,\n",
    "    \"train_runtime_seconds\": train_seconds,\n",
    "    \"dev\": eval_metrics,\n",
    "    \"test\": test_metrics,\n",
    "    \"parameter_counts\": param_counts,\n",
    "    \"efficiency\": efficiency,\n",
    "    \"kd_path\": str(kd_path),\n",
    "}\n",
    "utils.write_json(metrics, reports_dir / \"phase_c2_metrics.json\")\n",
    "metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
